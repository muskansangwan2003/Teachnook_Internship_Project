{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TEACHNOOK INTERNSHIP MAJOR PROJECT\n",
        "\n",
        "AUTHOR : MUSKAN\n",
        "\n",
        "TASK :Develop a chatbot equipped with sentiment analysis capabilities. The chatbot will analyze the\n",
        "sentiment of the user's input. The sentiment analysis component will determine whether the\n",
        "user's message expresses a positive, negative, or neutral sentiment.\n",
        "This project combines natural language processing (NLP) techniques, machine learning\n",
        "algorithms To Find the Sentiment Of User"
      ],
      "metadata": {
        "id": "fQQBbpmgmawu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUTxIMtmQjy3",
        "outputId": "99dc0659-9190-4814-a0bf-55c2970319e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: HAPPY\n",
            "Chatbot: The sentiment of your input is Positive.\n",
            "You: ANGRY\n",
            "Chatbot: The sentiment of your input is Negative.\n",
            "You: SAD\n",
            "Chatbot: The sentiment of your input is Negative.\n",
            "You: CLOUD NINE\n",
            "Chatbot: The sentiment of your input is Neutral.\n",
            "You: SMILING\n",
            "Chatbot: The sentiment of your input is Positive.\n",
            "You: EXIT\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download the movie_reviews dataset\n",
        "nltk.download(\"movie_reviews\")\n",
        "\n",
        "# Load the movie_reviews dataset\n",
        "positive_reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids(\"pos\")]\n",
        "negative_reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids(\"neg\")]\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    cleaned_text = re.sub('<.*?>', '', text)\n",
        "    # Remove special characters and numbers using regex\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z]', ' ', cleaned_text)\n",
        "    # Convert to lowercase\n",
        "    cleaned_text = cleaned_text.lower()\n",
        "    return cleaned_text\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(tokens):\n",
        "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "# Example preprocessing pipeline for positive reviews\n",
        "cleaned_positive_reviews = [clean_text(review) for review in positive_reviews]\n",
        "tokenized_positive_reviews = [tokenize(review) for review in cleaned_positive_reviews]\n",
        "filtered_positive_reviews = [remove_stopwords(tokens) for tokens in tokenized_positive_reviews]\n",
        "lemmatized_positive_reviews = [lemmatize(tokens) for tokens in filtered_positive_reviews]\n",
        "\n",
        "# Repeat the preprocessing steps for negative reviews\n",
        "\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Initialize the NLTK Vader Sentiment Analyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to perform sentiment analysis\n",
        "def analyze_sentiment(user_input):\n",
        "    sentiment_scores = sid.polarity_scores(user_input)\n",
        "    compound_score = sentiment_scores['compound']\n",
        "\n",
        "    if compound_score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif compound_score <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Simple command-line chatbot loop\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    sentiment = analyze_sentiment(user_input)\n",
        "\n",
        "    print(f\"Chatbot: The sentiment of your input is {sentiment}.\")"
      ]
    }
  ]
}